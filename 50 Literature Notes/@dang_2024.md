---
category: literaturenote
tags: 
citekey: dang_2024
status: unread
dateread:
---

> [!Cite]
> Dang, M.-H., Pham, T. H. T., Molli, P., Skaf-Molli, H., & Gaignard, A. (2024). _LLM4Schema.org: Generating Schema.org Markups with Large Language Models_.

>[!Synth]
>**Contribution**:: 
>
>**Related**:: 
>

>[!metadata]
> **FirstAuthor**:: Dang, Minh-Hoang  
> **Author**:: Pham, Thi Hoang Thi  
> **Author**:: Molli, Pascal  
> **Author**:: Skaf-Molli, Hala  
> **Author**:: Gaignard, Alban  
~    
> **Title**:: LLM4Schema.org: Generating Schema.org Markups with Large Language Models  
> **Year**:: 2024   
> **Citekey**:: dang_2024  
> **itemType**:: journalArticle  
> **Journal**:: **    

> [!LINK] 
>
>  [PDF](file:///home/cbrosch/Zotero/storage/9JQCBGXS/Dang%20et%20al.%20-%20LLM4Schema.org%20Generating%20Schema.org%20Markups%20with%20Large%20Language%20Models.pdf).

> [!Abstract]
>
> Integrating Schema.org markup into web pages has resulted in the generation of billions of RDF triples. However, around 75% of web pages still lack this critical markup. Large Language Models (LLMs) present a promising solution by automatically generating the missing Schema.org markup. Despite this potential, there is currently no benchmark to evaluate the markup quality produced by LLMs. This paper introduces LLM4Schema.org, an innovative approach for assessing the performance of LLMs in generating Schema.org markup. Unlike traditional methods, LLM4Schema.org does not require a predefined ground truth. Instead, it compares the quality of LLM-generated markup against human-generated markup. Our findings reveal that 40â€“50% of the markup produced by GPT-3.5 and GPT-4 is invalid, non-factual, or non-compliant with the Schema.org ontology. These errors underscore the limitations of LLMs in adhering strictly to structured ontologies like Schema.org without additional filtering and validation mechanisms. We demonstrate that specialized LLM-powered agents can effectively identify and eliminate these errors. After applying such filtering for both human and LLM-generated markup, GPT-4 shows notable improvements in quality and outperforms humans. LLM4Schema.org highlights both the potential and challenges of leveraging LLMs for semantic annotations, emphasizing the critical role of careful curation and validation in achieving reliable results.
>> 
# Notes
>.


# Annotations%% begin annotations %%



### Imported: 2025-02-13 11:23 am



Where does this claim come from? Sources don't seem to contain these numbers. ðŸ‘‡
<mark style="background-color: #ffd400">Quote</mark>
> Currently, semantic annotations are present in 41% of the worldâ€™s web pages, and 25% specifically using Schema.org markup [7, 10]. This leaves 75% of web pages without Schema.org markup and, thus, lacking structured data about their content.

<mark style="background-color: #ffd400">Quote</mark>
> Do LLMs generate more comprehensive Schema.org markup than humans, given the text of a web page?

<mark style="background-color: #e56eee">Contribution</mark>
> Schema.org markup curation agents: We developed three agents to curate Schema.org markup :  1) The Validity agent: Ensures syntactic correctness of the markup. This agent uses SHACL to verify that the markup adheres to the required structure and syntax. 2) The Factuality agent: Checks that every markup is grounded in the text of the web page. This agent is powered by an LLM, and we created a dedicated benchmark based on examples from the Schema.org documentation to evaluate its precision and recall. 3) The Compliance agent: Ensures that the content of the markup aligns with the expected types and values defined by the Schema.org documentation. This agent is also powered by an LLM, with its performance (precision/recall) evaluated on a dedicated benchmark using Schema.org examples.

<mark style="background-color: #e56eee">Contribution</mark>
> MeMR (Merged Markup Ratio) To compare the performance of humans and LLMs in the task of annotating web pages with Schema.org markup, we introduce MeMR, a scoring function that evaluates the coverage of two correct markups. MeMR returns a pair of numbers between 0 and 1; higher scores indicate a more comprehensive markup.

>![[image-5-x58-y281.png]]

### Imported: 2025-02-13 11:57 am



<mark style="background-color: #ff6666">Conclusion</mark>
> Thanks to LLM4Schema.org, we can sample web pages from the CommonCrawl and evaluate whether LLMs produce better Schema.org markup than humans. Our findings indicate that LLMs should not be used out-of-thebox for generating Schema.org markups, as they often produce invalid, unfactual, or non-compliant markups. For instance, with our best-performing LLM, GPT-4, over 40% of the generated markup is incorrect. However, after filtering the incorrect markup by LLM4Schema.org agents, filtered markup generated with GPT-4 can surpass human performance, achieving a MeMR score of 0.70 compared to 0.568 for humans. In contrast, GPT-3.5 does not outperform humans even after filtering with a MeMR score of 0.585 compared to 0.687 for humans. Additionally, we observed that GPT-3.5 and GPT-4 can enhance web pages by improving poorly filled types or utilizing less popular types, providing added value in specific contexts


%% end annotations %%

%% Import Date: 2025-02-13T11:57:18.393+01:00 %%
