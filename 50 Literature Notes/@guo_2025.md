---
category: literaturenote
tags: 
citekey: guo_2025
status: unread
dateread:
---

> [!Cite]
> Guo, Y., Li, Z., Jin, X., Liu, Y., Zeng, Y., Liu, W., Li, X., Yang, P., Bai, L., Guo, J., & Cheng, X. (2025). Retrieval-Augmented Code Generation for Universal Information Extraction. In D. F. Wong, Z. Wei, & M. Yang (Eds.), _Natural Language Processing and Chinese Computing_ (pp. 30–42). Springer Nature. [https://doi.org/10.1007/978-981-97-9434-8_3](https://doi.org/10.1007/978-981-97-9434-8_3)

>[!Synth]
>**Contribution**:: 
>
>**Related**:: 
>

>[!metadata]
> **FirstAuthor**:: Guo, Yucan  
> **Author**:: Li, Zixuan  
> **Author**:: Jin, Xiaolong  
> **Author**:: Liu, Yantao  
> **Author**:: Zeng, Yutao  
> **Author**:: Liu, Wenxuan  
> **Author**:: Li, Xiang  
> **Author**:: Yang, Pan  
> **Author**:: Bai, Long  
> **Author**:: Guo, Jiafeng  
> **Author**:: Cheng, Xueqi  
~> **FirstEditor**:: Wong, Derek F.  
> **Editor**:: Wei, Zhongyu  
> **Editor**:: Yang, Muyun  
~    
> **Title**:: Retrieval-Augmented Code Generation for Universal Information Extraction  
> **Year**:: 2025   
> **Citekey**:: guo_2025  
> **itemType**:: conferencePaper  
> **Publisher**:: Springer Nature  
> **Location**:: Singapore   
> **Pages**:: 30-42  
> **DOI**:: 10.1007/978-981-97-9434-8_3  
> **ISBN**:: 978-981-97-9434-8    

> [!LINK] 
>
>  [PDF](file:///home/cbrosch/Zotero/storage/7U6QX8GF/Guo%20et%20al.%20-%202025%20-%20Retrieval-Augmented%20Code%20Generation%20for Universal%20Information%20Extraction.pdf).

> [!Abstract]
>
> Information Extraction (IE) aims to extract structural knowledge (e.g., entities, relations, events) from natural language texts. Recently, Large Language Models (LLMs) with code-style prompts have demonstrated powerful capabilities in IE tasks. However, adopting code LLMs to conduct IE tasks still has two challenges: (1) It still lacks a unified code-style prompt for different IE tasks since existing methods use task-specific prompts for separate IE tasks. (2) It still lacks an effective in-context learning (ICL) method to encourage LLMs to conduct IE tasks precisely, considering some powerful LLMs are close-sourced and not trainable. Therefore, this paper proposes a code generation framework for Universal IE (UIE) tasks called Code4UIE. Specifically, for the first challenge, Code4UIE designs a unified code-style schema for various IE tasks via Python classes. By so doing, different IE tasks can be associated, and LLMs can learn from various IE tasks effectively. For the second challenge, Code4UIE adopts a retrieval-augmented mechanism to comprehensively utilize the ICL ability of LLMs. Extensive experiments on five representative IE tasks across nine datasets demonstrate the effectiveness of the Code4UIE framework.
>> 
# Notes
>.


# Annotations%% begin annotations %%



### Imported: 2025-01-21 11:48 am



<mark style="background-color: #ffd400">Quote</mark>
> With the code-style schemas serving as its input, Code4UIE is capable of decoding heterogeneous IE structures as uniform code generation. To accomplish this, we design two types of code-style prompts that guide the model in generating appropriate codes. To understand complex text expressions, we enhance Code4UIE with unified example retrieval strategies, which help the model generalize better from the training examples and adapt to new tasks more effectively.

<mark style="background-color: #e56eee">Contribution</mark>
> In summary, our contributions are as follows:  1. We propose a schema-based representation method that can universally define various task-specific schemas in IE tasks in terms of Python classes.  2. We transform IE tasks into a universal code generation task based on the schema representation method, and further propose a retrievalaugmented code generation framework based on LLMs, Code4UIE, to tackle this universal code generation task. Code4UIE is equipped with unified example retrieval strategies to help LLMs understand complex text expressions better by in-context learning.  3. Experimental results on five IE tasks over nine datasets demonstrate that Code4UIE outperforms current LLMs-based IE approaches on all IE tasks.

![[image-4-x63-y572.png]]

<mark style="background-color: #2ea8e5">Section</mark>
> Schema Representation

<mark style="background-color: #2ea8e5">Section</mark>
> Entity Definition

<mark style="background-color: #ffd400">Quote</mark>
> To define entities by Python classes, a Python base class, "Entity", is served as the parent class for all entity classes, with each specific entity type corresponding to a subclass of "Entity".


> ![[image-3-x69-y128.png]]

<mark style="background-color: #2ea8e5">Section</mark>
> Relation Definition


> ![[image-3-x304-y567.png]]

<mark style="background-color: #2ea8e5">Section</mark>
> Event Definition

> ![[image-3-x303-y127.png]]


> 2-stage Prompt

<mark style="background-color: #ffd400">Quote</mark>
> (1) The code generation task in Stage 1 is to complete an import statement (e.g., from  Entity import Person) instead of generating instances of Python class.  (2) The schema definition code in Stage 2 only contains those classes related to the import statement completed in Stage 1 (e.g., class  Entity and class Person), while that of the 1-stage prompt and Stage 1 prompt of the 2-stage prompt should contain all the Python classes related to the task-specific schema.


 >![[image-5-x61-y518.png]]

<mark style="background-color: #2ea8e5">Section</mark>
> In-context Example Retrieval Strategies

<mark style="background-color: #2ea8e5">Section</mark>
> Sentence Embedding-based Retrieval Strategy

<mark style="background-color: #ffd400">Quote</mark>
> The sentence embedding-based retrieval strategy uses MPNet (Song et al., 2020) to encode the input sentence and sentences in the training set. The k samples with the highest similarity to the input sentence in the training set will be selected as incontext examples, in which the similarity calculation is based on Euclidean distance. This strategy is employed and tested in all five IE tasks.

<mark style="background-color: #2ea8e5">Section</mark>
> Anonymous Sentence Embedding-based Retrieval Strategy

<mark style="background-color: #ffd400">Quote</mark>
> Considering that selecting samples with higher similarity in terms of context and entity types, rather than specific entity text information, is more effective for complex IE tasks like EE, we propose an anonymous sentence embedding-based retrieval strategy. The key idea of this anonymous strategy is to use a NER model, FLERT (Schweter and Akbik, 2020), to replace entities in a sentence by their entity types when encoding, and utilizing that anonymous information for the calculation of sentence similarity when performing in-context example retrieval.

<mark style="background-color: #ff6666">Conclusion</mark>
> In this paper, we proposed a retrieval-augmented code generation framework for universal information extraction, namely Code4UIE, which formulates different IE tasks as a unified Python instance code completion task. Code4UIE adopts two effective in-context example retrieval strategies, which enable it to retrieve in-context examples that are better suited for the current sentence and task, resulting in a significant improvement in IE performance. Experimental results demonstrate that Code4UIE surpasses current LLMs-based IE approaches on all IE tasks.


%% end annotations %%

%% Import Date: 2025-01-21T13:05:44.603+01:00 %%
